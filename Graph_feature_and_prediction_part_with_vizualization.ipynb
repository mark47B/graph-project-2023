{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0147cb2f",
   "metadata": {},
   "source": [
    "Gamma = Г(u) - число соседей вершины u (степень вершины u)\n",
    "n = |V| - число вершин\n",
    "m = |E_G| - число ребер\n",
    "l=0.2\n",
    "t_min - самая ранняя наблюдаемая отметка по всем ребрам сети\n",
    "t_max - самая последняя наблюдаемая отметка по всем ребрам сети\n",
    "t - временная метка ребра\n",
    "\n",
    "Вектор признаков описывает ребро черех активности узлов, которое оно соединяет\n",
    "Вектор признаков длиной 3*7*4 = 84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db390459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "fd174804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_degree(numbers_of_nodes:np.array, adjacency_matrix:np.array):\n",
    "    return np.sum(adjacency_matrix[numbers_of_nodes,:],axis=1)\n",
    "\n",
    "def common_neighbours(u:int, v:int, adjacency_matrix:np.array) -> int:\n",
    "    return np.sum(np.where(adjacency_matrix[u,:]+adjacency_matrix[v,:] != 0, 1, 0))\n",
    "\n",
    "def adamic_adar(u:int, v:int, adjacency_matrix:np.array) -> float:\n",
    "    return np.sum(1/node_degree(np.nonzero(adjacency_matrix[u,:]+adjacency_matrix[v,:]),adjacency_matrix))\n",
    "\n",
    "def jaccard_coefficient(u:int, v:int, adjacency_matrix:np.array) -> float:\n",
    "    return np.sum(np.where(adjacency_matrix[u,:]-adjacency_matrix[v,:] == 0, 1, 0))/np.sum(\n",
    "        np.where(adjacency_matrix[u,:]+adjacency_matrix[v,:] != 0, 1, 0))\n",
    "\n",
    "def preferential_attachment(u:int, v:int, adjacency_matrix:np.array) -> int:\n",
    "    return np.prod(node_degree(np.array([u,v]),adjacency_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "552d8129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 функции для вычисления весов\n",
    "\n",
    "# Во все функции в качестве t можно передавать np массив временных меток всех ребер\n",
    "\n",
    "def temporal_weighting_w_linear(t:np.array,t_min:int,t_max:int,l:float=0.2) -> float:\n",
    "    return l+(1-l)*(t-t_min)/(t_max-t_min) # w_linear\n",
    "def temporal_weighting_w_exponential(t:np.array,t_min:float,t_max:float,l:float=0.2) -> float:\n",
    "    return l+(1-l)*(np.exp(3*(t-t_min)/(t_max-t_min))-1)/(np.exp(3)-1) # w_exponential \n",
    "def temporal_weighting_w_square_root(t:np.array,t_min:float,t_max:float,l:float=0.2) -> float:\n",
    "    return l+(1-l)*np.sqrt((t-t_min)/(t_max-t_min)) #w_square_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e75e451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 функций для аггрегации весов ребер, прилегающих к узлу\n",
    "\n",
    "# edge_weights - np array размерности 2; i-ая строка - веса ребер, прилегающих к i-ой вершине \n",
    "\n",
    "def aggregation_of_node_activity_zeroth_quantile(edges_weights:list)-> float:\n",
    "    return [np.quantile(weights_set,0) for weights_set in edges_weights]\n",
    "def aggregation_of_node_activity_first_quantile(edges_weights:list)-> float:\n",
    "    return [np.quantile(weights_set,0.25) for weights_set in edges_weights]\n",
    "def aggregation_of_node_activity_second_quantile(edges_weights:list)-> float:\n",
    "    return [np.quantile(weights_set,0.5) for weights_set in edges_weights]\n",
    "def aggregation_of_node_activity_third_quantile(edges_weights:list)-> float:\n",
    "    return [np.quantile(weights_set,0.75) for weights_set in edges_weights]\n",
    "def aggregation_of_node_activity_fourth_quantile(edges_weights:list)-> float:\n",
    "    return [np.quantile(weights_set,1) for weights_set in edges_weights]\n",
    "def aggregation_of_node_activity_sum(edges_weights:list)-> float:\n",
    "    return [np.sum(weights_set,0) for weights_set in edges_weights]\n",
    "def aggregation_of_node_activity_mean(edges_weights:list)-> float:\n",
    "    return [np.mean(weights_set,0) for weights_set in edges_weights]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "bae0fd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 функции для объединения статистик по парам узлов\n",
    "\n",
    "def combining_node_activity_sum(aggregarion_node_one:np.array, aggregation_node_two:np.array)-> float:\n",
    "    return aggregarion_node_one + aggregation_node_two\n",
    "def combining_node_activity_absolute_diference(aggregarion_node_one:np.array, aggregation_node_two:np.array)-> float:\n",
    "    return np.abs(aggregarion_node_one - aggregation_node_two)\n",
    "def combining_node_activity_minimum(aggregarion_node_one:np.array, aggregation_node_two:np.array)-> float:\n",
    "    return np.min(np.concatenate([aggregarion_node_one[:, np.newaxis], aggregation_node_two[:, np.newaxis]], axis=1), axis=1)\n",
    "def combining_node_activity_maximum(aggregarion_node_one:np.array, aggregation_node_two:np.array)-> float:\n",
    "    return np.max(np.concatenate([aggregarion_node_one[:, np.newaxis], aggregation_node_two[:, np.newaxis]], axis=1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2127f857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_weighting(edge: pd.DataFrame, t_min: int, t_max: int):\n",
    "    '''\n",
    "    Взвешивание во времени: расчет трех весов для каждого ребра по их временным меткам\n",
    "    '''\n",
    "    edge['weight_linear'] = temporal_weighting_w_linear(edge['timestamp'],t_min,t_max)\n",
    "    edge['weight_exponential'] = temporal_weighting_w_exponential(edge['timestamp'],t_min,t_max)\n",
    "    edge['weight_square_root'] = temporal_weighting_w_square_root(edge['timestamp'],t_min,t_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c8c6d6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregation_of_node_activity(node: pd.DataFrame, edges_weights_for_node: pd.DataFrame):\n",
    "    \n",
    "    '''\n",
    "    Агрегация активности узлов на основе 7 функций: \n",
    "    нулевой, первый,второй,третий,чертвертый квантили; сумма и среднее\n",
    "    по весам ребер смежных с вершиной\n",
    "    '''\n",
    "    \n",
    "    node['node_activity_zeroth_quantile_wl'] = aggregation_of_node_activity_zeroth_quantile(edges_weights_for_node[\"weight_linear\"])\n",
    "    node['node_activity_first_quantile_wl'] = aggregation_of_node_activity_first_quantile(edges_weights_for_node[\"weight_linear\"])\n",
    "    node['node_activity_second_quantile_wl'] = aggregation_of_node_activity_second_quantile(edges_weights_for_node[\"weight_linear\"])\n",
    "    node['node_activity_third_quantile_wl'] = aggregation_of_node_activity_third_quantile(edges_weights_for_node[\"weight_linear\"])\n",
    "    node['node_activity_fourth_quantile_wl'] = aggregation_of_node_activity_fourth_quantile(edges_weights_for_node[\"weight_linear\"])\n",
    "    node['node_activity_sum_wl'] = aggregation_of_node_activity_sum(edges_weights_for_node[\"weight_linear\"])\n",
    "    node['node_activity_mean_wl'] = aggregation_of_node_activity_mean(edges_weights_for_node[\"weight_linear\"])\n",
    "    \n",
    "    node['node_activity_zeroth_quantile_we'] = aggregation_of_node_activity_zeroth_quantile(edges_weights_for_node[\"weight_exponential\"])\n",
    "    node['node_activity_first_quantile_we'] = aggregation_of_node_activity_first_quantile(edges_weights_for_node[\"weight_exponential\"])\n",
    "    node['node_activity_second_quantile_we'] = aggregation_of_node_activity_second_quantile(edges_weights_for_node[\"weight_exponential\"])\n",
    "    node['node_activity_third_quantile_we'] = aggregation_of_node_activity_third_quantile(edges_weights_for_node[\"weight_exponential\"])\n",
    "    node['node_activity_fourth_quantile_we'] = aggregation_of_node_activity_fourth_quantile(edges_weights_for_node[\"weight_exponential\"])\n",
    "    node['node_activity_sum_we'] = aggregation_of_node_activity_sum(edges_weights_for_node[\"weight_exponential\"])\n",
    "    node['node_activity_mean_we'] = aggregation_of_node_activity_mean(edges_weights_for_node[\"weight_exponential\"])\n",
    "    \n",
    "    node['node_activity_zeroth_quantile_wsr'] = aggregation_of_node_activity_zeroth_quantile(edges_weights_for_node[\"weight_square_root\"])\n",
    "    node['node_activity_first_quantile_wsr'] = aggregation_of_node_activity_first_quantile(edges_weights_for_node[\"weight_square_root\"])\n",
    "    node['node_activity_second_quantile_wsr'] = aggregation_of_node_activity_second_quantile(edges_weights_for_node[\"weight_square_root\"])\n",
    "    node['node_activity_third_quantile_wsr'] = aggregation_of_node_activity_third_quantile(edges_weights_for_node[\"weight_square_root\"])\n",
    "    node['node_activity_fourth_quantile_wsr'] = aggregation_of_node_activity_fourth_quantile(edges_weights_for_node[\"weight_square_root\"])\n",
    "    node['node_activity_sum_wsr'] = aggregation_of_node_activity_sum(edges_weights_for_node[\"weight_square_root\"])\n",
    "    node['node_activity_mean_wsr'] = aggregation_of_node_activity_mean(edges_weights_for_node[\"weight_square_root\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "5dc55292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combining_node_activity(node: pd.DataFrame)->pd.DataFrame:\n",
    "    \n",
    "    '''\n",
    "    Объединение активности узлов для формирования векторного описания\n",
    "    ребра на основе 4 функций:\n",
    "    сумма, абсолютная разность, мин, макс \n",
    "    по парным активностям инцидентных вершин\n",
    "    \n",
    "    '''\n",
    "    values = node[['node_activity_zeroth_quantile_wl',\n",
    "    'node_activity_first_quantile_wl',\n",
    "    'node_activity_second_quantile_wl',\n",
    "    'node_activity_third_quantile_wl',\n",
    "    'node_activity_fourth_quantile_wl',\n",
    "    'node_activity_sum_wl',\n",
    "    'node_activity_mean_wl',\n",
    "    \n",
    "    'node_activity_zeroth_quantile_we',\n",
    "    'node_activity_first_quantile_we',\n",
    "    'node_activity_second_quantile_we',\n",
    "    'node_activity_third_quantile_we',\n",
    "    'node_activity_fourth_quantile_we',\n",
    "    'node_activity_sum_we',\n",
    "    'node_activity_mean_we',\n",
    "    \n",
    "    'node_activity_zeroth_quantile_wsr',\n",
    "    'node_activity_first_quantile_wsr',\n",
    "    'node_activity_second_quantile_wsr',\n",
    "    'node_activity_third_quantile_wsr',\n",
    "    'node_activity_fourth_quantile_wsr',\n",
    "    'node_activity_sum_wsr',\n",
    "    'node_activity_mean_wsr']].values\n",
    "\n",
    "    num_of_nodes = node.shape[0]\n",
    "    num_of_feature = 21\n",
    "\n",
    "    \n",
    "    combined_values = []\n",
    "    start_nodes_vector = []\n",
    "\n",
    "    for i, row in enumerate(values):\n",
    "        repeated_row = np.tile(row, num_of_nodes - i - 1)\n",
    "        repeated_node = np.tile(i, num_of_nodes - i - 1)\n",
    "        \n",
    "        combined_values.extend(repeated_row)\n",
    "        start_nodes_vector.extend(repeated_node)\n",
    "\n",
    "\n",
    "    # Преобразование объединенных значений в массив NumPy\n",
    "    first_combined_array = np.array(combined_values)\n",
    "    \n",
    "    end_nodes_vector = list(np.concatenate([np.arange(i, num_of_nodes) for i in range(1, num_of_nodes)]))\n",
    "    \n",
    "    # Замена номеров строк на значения из DataFrame и объединение в один вектор\n",
    "    second_combined_array = np.concatenate([values[end_nodes_vector[i]] for i in range(len(end_nodes_vector))])\n",
    "    \n",
    "    feature_by_sym = combining_node_activity_sum(first_combined_array,second_combined_array)\n",
    "    feature_by_abs_dif = combining_node_activity_absolute_diference(first_combined_array,second_combined_array)\n",
    "    feature_by_min = combining_node_activity_minimum(first_combined_array,second_combined_array)\n",
    "    feature_by_max = combining_node_activity_maximum(first_combined_array,second_combined_array)\n",
    "\n",
    "    \n",
    "    all_feature = [np.concatenate([feature_by_sym[i:i+num_of_feature], \n",
    "                                   feature_by_abs_dif[i:i+num_of_feature], \n",
    "                                   feature_by_min[i:i+num_of_feature], \n",
    "                                   feature_by_max[i:i+num_of_feature]]) \n",
    "                   for i in range(0, feature_by_sym.shape[0], num_of_feature)]\n",
    "    \n",
    "    feature_column_name = \"feature_vector\"\n",
    "    Edge_feature = pd.DataFrame({\"start_node\":start_nodes_vector, \"end_node\":end_nodes_vector, feature_column_name: all_feature})\n",
    "    return (Edge_feature,feature_column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "4cb55866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combining_node_activity(node: pd.DataFrame)->pd.DataFrame:\n",
    "    \n",
    "    '''\n",
    "    Объединение активности узлов для формирования векторного описания\n",
    "    ребра на основе 4 функций:\n",
    "    сумма, абсолютная разность, мин, макс \n",
    "    по парным активностям инцидентных вершин\n",
    "    \n",
    "    '''\n",
    "    values = node[['node_activity_zeroth_quantile_wl',\n",
    "    'node_activity_first_quantile_wl',\n",
    "    'node_activity_second_quantile_wl',\n",
    "    'node_activity_third_quantile_wl',\n",
    "    'node_activity_fourth_quantile_wl',\n",
    "    'node_activity_sum_wl',\n",
    "    'node_activity_mean_wl',\n",
    "    \n",
    "    'node_activity_zeroth_quantile_we',\n",
    "    'node_activity_first_quantile_we',\n",
    "    'node_activity_second_quantile_we',\n",
    "    'node_activity_third_quantile_we',\n",
    "    'node_activity_fourth_quantile_we',\n",
    "    'node_activity_sum_we',\n",
    "    'node_activity_mean_we',\n",
    "    \n",
    "    'node_activity_zeroth_quantile_wsr',\n",
    "    'node_activity_first_quantile_wsr',\n",
    "    'node_activity_second_quantile_wsr',\n",
    "    'node_activity_third_quantile_wsr',\n",
    "    'node_activity_fourth_quantile_wsr',\n",
    "    'node_activity_sum_wsr',\n",
    "    'node_activity_mean_wsr']].values\n",
    "\n",
    "    num_of_nodes = node.shape[0]\n",
    "    num_of_feature = 21\n",
    "    feature_column_name = \"feature_vector\"\n",
    "\n",
    "\n",
    "    start_nodes_vector = np.repeat(np.arange(len(values)), num_of_nodes - np.arange(len(values)) - 1)\n",
    "    \n",
    "    end_nodes_vector = list(np.concatenate([np.arange(i, num_of_nodes) for i in range(1, num_of_nodes)]))\n",
    "    \n",
    "    first_combined_array = np.concatenate([values[start_nodes_vector[i]] for i in range(len(start_nodes_vector))])\n",
    "    \n",
    "    second_combined_array = np.concatenate([values[end_nodes_vector[i]] for i in range(len(end_nodes_vector))])\n",
    "    \n",
    "    feature_by_sym = combining_node_activity_sum(first_combined_array,second_combined_array)\n",
    "    feature_by_abs_dif = combining_node_activity_absolute_diference(first_combined_array,second_combined_array)\n",
    "    feature_by_min = combining_node_activity_minimum(first_combined_array,second_combined_array)\n",
    "    feature_by_max = combining_node_activity_maximum(first_combined_array,second_combined_array)\n",
    "\n",
    "    \n",
    "    all_feature = [np.concatenate([feature_by_sym[i:i+num_of_feature], \n",
    "                                   feature_by_abs_dif[i:i+num_of_feature], \n",
    "                                   feature_by_min[i:i+num_of_feature], \n",
    "                                   feature_by_max[i:i+num_of_feature]]) \n",
    "                   for i in range(0, feature_by_sym.shape[0], num_of_feature)]\n",
    "    \n",
    "    Edge_feature = pd.DataFrame({\"start_node\":start_nodes_vector, \"end_node\":end_nodes_vector,feature_column_name:all_feature})\n",
    "\n",
    "    return (Edge_feature,feature_column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "8f4f3690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combining_node_activity_for_absent_edge(node: pd.DataFrame, edge: pd.DataFrame)->pd.DataFrame:\n",
    "    \n",
    "    '''\n",
    "    Объединение активности узлов для формирования векторного описания\n",
    "    ребра на основе 4 функций:\n",
    "    сумма, абсолютная разность, мин, макс \n",
    "    по парным активностям инцидентных вершин\n",
    "    \n",
    "    '''\n",
    "    values = node[['node_activity_zeroth_quantile_wl',\n",
    "    'node_activity_first_quantile_wl',\n",
    "    'node_activity_second_quantile_wl',\n",
    "    'node_activity_third_quantile_wl',\n",
    "    'node_activity_fourth_quantile_wl',\n",
    "    'node_activity_sum_wl',\n",
    "    'node_activity_mean_wl',\n",
    "    \n",
    "    'node_activity_zeroth_quantile_we',\n",
    "    'node_activity_first_quantile_we',\n",
    "    'node_activity_second_quantile_we',\n",
    "    'node_activity_third_quantile_we',\n",
    "    'node_activity_fourth_quantile_we',\n",
    "    'node_activity_sum_we',\n",
    "    'node_activity_mean_we',\n",
    "    \n",
    "    'node_activity_zeroth_quantile_wsr',\n",
    "    'node_activity_first_quantile_wsr',\n",
    "    'node_activity_second_quantile_wsr',\n",
    "    'node_activity_third_quantile_wsr',\n",
    "    'node_activity_fourth_quantile_wsr',\n",
    "    'node_activity_sum_wsr',\n",
    "    'node_activity_mean_wsr']].values\n",
    "\n",
    "    num_of_nodes = node.shape[0]\n",
    "    num_of_feature = 21\n",
    "    feature_column_name = \"feature_vector\"\n",
    "\n",
    "\n",
    "    start_nodes_vector = np.repeat(np.arange(len(values)), num_of_nodes - np.arange(len(values)) - 1)\n",
    "    \n",
    "    end_nodes_vector = list(np.concatenate([np.arange(i, num_of_nodes) for i in range(1, num_of_nodes)]))\n",
    "    \n",
    "    Edge_feature = pd.DataFrame({\"start_node\":start_nodes_vector, \"end_node\":end_nodes_vector})\n",
    "\n",
    "    # Оставляем только ребра, которых нет в статичном графе\n",
    "    df_merged = Edge_feature.merge(edge[['start_node', 'end_node']], on=['start_node', 'end_node'], how='left', indicator=True)\n",
    "    df_filtered = df_merged[df_merged['_merge'] == 'left_only']\n",
    "    df_filtered = df_filtered.drop(columns='_merge')\n",
    "    Edge_feature = df_filtered\n",
    "    \n",
    "    start_nodes_vector = Edge_feature['start_node'].values\n",
    "    end_nodes_vector = Edge_feature['end_node'].values\n",
    "\n",
    "    \n",
    "    first_combined_array = np.concatenate([values[start_nodes_vector[i]] for i in range(len(start_nodes_vector))])\n",
    "    \n",
    "    second_combined_array = np.concatenate([values[end_nodes_vector[i]] for i in range(len(end_nodes_vector))])\n",
    "    \n",
    "    feature_by_sym = combining_node_activity_sum(first_combined_array,second_combined_array)\n",
    "    feature_by_abs_dif = combining_node_activity_absolute_diference(first_combined_array,second_combined_array)\n",
    "    feature_by_min = combining_node_activity_minimum(first_combined_array,second_combined_array)\n",
    "    feature_by_max = combining_node_activity_maximum(first_combined_array,second_combined_array)\n",
    "\n",
    "    \n",
    "    all_feature = [np.concatenate([feature_by_sym[i:i+num_of_feature], \n",
    "                                   feature_by_abs_dif[i:i+num_of_feature], \n",
    "                                   feature_by_min[i:i+num_of_feature], \n",
    "                                   feature_by_max[i:i+num_of_feature]]) \n",
    "                   for i in range(0, feature_by_sym.shape[0], num_of_feature)]\n",
    "    \n",
    "    Edge_feature[feature_column_name] =  all_feature\n",
    "    return (Edge_feature,feature_column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "455b39f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_static_topological_features(df: pd.DataFrame):\n",
    "    '''\n",
    "    Рассчет статичных топологических признаков\n",
    "    '''\n",
    "    df[\"common_neighbours\"] = df.apply(lambda row: common_neighbours(row[\"start_node\"],row[\"end_node\"],adjacency_matrix), axis=1)\n",
    "    df[\"adamic_adar\"] = df.apply(lambda row: adamic_adar(row[\"start_node\"],row[\"end_node\"],adjacency_matrix), axis=1)\n",
    "    df[\"jaccard_coefficient\"] = df.apply(lambda row: jaccard_coefficient(row[\"start_node\"],row[\"end_node\"],adjacency_matrix), axis=1)\n",
    "    df[\"preferential_attachment\"] = df.apply(lambda row: preferential_attachment(row[\"start_node\"],row[\"end_node\"],adjacency_matrix), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "7a3f2c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_nan(df, columns, start_node_column, end_node_column):\n",
    "    '''\n",
    "    Замена NaN на [] в числовых ячейках и сопоставление номеров для вершин,\n",
    "    которые были только либо в end_node, либо в start_node\n",
    "    '''\n",
    "    \n",
    "    for column in columns:\n",
    "        df[column] = df[column].apply(lambda x: [] if not isinstance(x, list) else x)\n",
    "    \n",
    "    df[start_node_column] = np.where(np.isnan(df[start_node_column]), df[end_node_column], df[start_node_column])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "fbe33e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_edges_weights_adjacent_to_node(edge: pd.DataFrame):\n",
    "    \n",
    "    '''\n",
    "    Формирование датафрейма с весами примыкающих к вершине ребер.\n",
    "    Строка соответствует определенной вершине.\n",
    "    '''\n",
    "    grouped_by_start_node = edge.drop(['end_node',\"number\",\"timestamp\"], \n",
    "                                      axis=1).groupby(\"start_node\").agg(\n",
    "    {'weight_linear': list, 'weight_exponential': list,\n",
    "     'weight_square_root': list}).reset_index()\n",
    "    grouped_by_end_node = edge.drop(['start_node',\"number\",\"timestamp\"], \n",
    "                                    axis=1).groupby(\"end_node\").agg(\n",
    "    {'weight_linear': list, 'weight_exponential': list,\n",
    "     'weight_square_root': list}).reset_index()\n",
    "    \n",
    "    edges_weights_for_node = grouped_by_start_node.merge(\n",
    "        grouped_by_end_node, left_on='start_node', right_on='end_node', how='outer')\n",
    "\n",
    "\n",
    "    edges_weights_for_node = replace_nan(edges_weights_for_node,\n",
    "                                         ['weight_linear_x', 'weight_exponential_x',\n",
    "                                          \"weight_square_root_x\",\"weight_linear_y\", \n",
    "                                          'weight_exponential_y', \"weight_square_root_y\"],\n",
    "                                         'start_node',\"end_node\")\n",
    "    \n",
    "    edges_weights_for_node[\"weight_linear\"]=edges_weights_for_node[\n",
    "        \"weight_linear_x\"] + edges_weights_for_node[\"weight_linear_y\"]\n",
    "    edges_weights_for_node[\"weight_exponential\"]=edges_weights_for_node[\n",
    "        \"weight_exponential_x\"]+edges_weights_for_node[\"weight_exponential_y\"]\n",
    "    edges_weights_for_node[\"weight_square_root\"]=edges_weights_for_node[\n",
    "        \"weight_square_root_x\"]+edges_weights_for_node[\"weight_square_root_y\"]\n",
    "    edges_weights_for_node = edges_weights_for_node.drop(\n",
    "        [\"end_node\",'weight_linear_x', 'weight_exponential_x',\n",
    "         \"weight_square_root_x\",\"weight_linear_y\", 'weight_exponential_y', \n",
    "         \"weight_square_root_y\"], axis=1)\n",
    "\n",
    "    edges_weights_for_node['start_node'] = edges_weights_for_node['start_node'].astype(int)\n",
    "\n",
    "    edges_weights_for_node[[\n",
    "        \"weight_linear\",\"weight_exponential\",\"weight_square_root\"]] = edges_weights_for_node[[\n",
    "        \"weight_linear\",\"weight_exponential\",\"weight_square_root\"]].apply(lambda x: np.array(x))\n",
    "\n",
    "    edges_weights_for_node=edges_weights_for_node.sort_values(by='start_node')\n",
    "    \n",
    "    return edges_weights_for_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "2d58862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list_cell(df: pd.DataFrame, column_name:str):\n",
    "    '''\n",
    "    Разбиение списка на отдельные столбцы с автоматической генерацией имен\n",
    "    '''\n",
    "    return pd.concat([df.drop(column_name, axis=1),\n",
    "                df[column_name].apply(lambda x: pd.Series(x))],\n",
    "               axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "195ed393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_with_temporal_graph_number(df: pd.DataFrame,node: pd.DataFrame):\n",
    "    '''\n",
    "    Сопоставление номера в статичном графе номеру из временного графа\n",
    "    '''\n",
    "    df = pd.merge(df, node[['number',\"number_in_temporal_graph\"]],\n",
    "                            left_on='start_node', right_on='number')\n",
    "    \n",
    "    df = pd.merge(df, node[['number',\"number_in_temporal_graph\"]],\n",
    "                            left_on='end_node', right_on='number')\n",
    "    \n",
    "    df = df.drop([\"number_x\",\"number_y\"], axis=1)\n",
    "    df = df.rename(columns={'number_in_temporal_graph_x': 'number_in_temporal_graph_start_node'})\n",
    "    df = df.rename(columns={'number_in_temporal_graph_y': 'number_in_temporal_graph_end_node'})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "eae1dd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_for_edges(edge: pd.DataFrame, node: pd.DataFrame, adjacency_matrix: np.array, t_min:int, t_max:int):\n",
    "    '''\n",
    "    Получение датафрейма с признаками для ребер\n",
    "    '''\n",
    "    temporal_weighting(edge, t_min, t_max)\n",
    "    \n",
    "    edges_weights_adjacent_to_node = make_edges_weights_adjacent_to_node(edge)\n",
    "    \n",
    "    aggregation_of_node_activity(node,edges_weights_adjacent_to_node)\n",
    "    \n",
    "    Edge_feature,feature_column_name = combining_node_activity(node)\n",
    "\n",
    "    Edge_feature = merge_with_temporal_graph_number(Edge_feature, node)\n",
    "    \n",
    "    count_static_topological_features(Edge_feature)\n",
    "            \n",
    "    Edge_feature = split_list_cell(Edge_feature, feature_column_name)\n",
    "\n",
    "    return Edge_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "b131c448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_for_absent_edges(edge: pd.DataFrame, node: pd.DataFrame, adjacency_matrix: np.array, t_min:int, t_max:int):\n",
    "    '''\n",
    "    Получение датафрейма с признаками для ребер\n",
    "    '''\n",
    "    temporal_weighting(edge, t_min, t_max)\n",
    "    \n",
    "    edges_weights_adjacent_to_node = make_edges_weights_adjacent_to_node(edge)\n",
    "    \n",
    "    aggregation_of_node_activity(node,edges_weights_adjacent_to_node)\n",
    "    \n",
    "    Edge_feature,feature_column_name = combining_node_activity_for_absent_edge(node,edge)\n",
    "\n",
    "    Edge_feature = merge_with_temporal_graph_number(Edge_feature, node)\n",
    "    \n",
    "    count_static_topological_features(Edge_feature)\n",
    "            \n",
    "    Edge_feature = split_list_cell(Edge_feature, feature_column_name)\n",
    "\n",
    "    return Edge_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "aaac5b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "Networks = ['email-Eu-core-temporal', 'munmun_digg_reply', 'opsahi-ucsocial','radoslaw_email','soc-sign-bitcoinalpha', 'sx-mathoverflow']\n",
    "\n",
    "networks_files_names = [ f'datasets/{i}/out.{i}' for i in Networks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "2107c815",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_datasets = 6\n",
    "datasets_info = {'Network': ['email-Eu-core-temporal', 'munmun_digg_reply', 'opsahi-ucsocial','radoslaw_email','soc-sign-bitcoinalpha', 'sx-mathoverflow'],\n",
    "'Label': ['EU','D-rep','UC','Rado','bitA','SX-MO'],\n",
    "'Category': ['Social',\"Social\",\"Information\",\"Social\",\"Social\",\"Social\"],\n",
    "'Edge type': ['Multi','Simple','Multi','Multi','Simple','Multi'],\n",
    "'Path': networks_files_names}\n",
    "\n",
    "datasets_info = pd.DataFrame(datasets_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "6e27c593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Network</th>\n",
       "      <th>Label</th>\n",
       "      <th>Category</th>\n",
       "      <th>Nodes</th>\n",
       "      <th>Edge type</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>email-Eu-core-temporal</td>\n",
       "      <td>EU</td>\n",
       "      <td>Social</td>\n",
       "      <td>986</td>\n",
       "      <td>Multi</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>munmun_digg_reply</td>\n",
       "      <td>D-rep</td>\n",
       "      <td>Social</td>\n",
       "      <td>30398</td>\n",
       "      <td>Simple</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>opsahi-ucsocial</td>\n",
       "      <td>UC</td>\n",
       "      <td>Information</td>\n",
       "      <td>1899</td>\n",
       "      <td>Multi</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>radoslaw_email</td>\n",
       "      <td>Rado</td>\n",
       "      <td>Social</td>\n",
       "      <td>167</td>\n",
       "      <td>Multi</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soc-sign-bitcoinalpha</td>\n",
       "      <td>bitA</td>\n",
       "      <td>Social</td>\n",
       "      <td>3783</td>\n",
       "      <td>Simple</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sx-mathoverflow</td>\n",
       "      <td>SX-MO</td>\n",
       "      <td>Social</td>\n",
       "      <td>24818</td>\n",
       "      <td>Multi</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Network  Label     Category  Nodes Edge type  Path\n",
       "0  email-Eu-core-temporal     EU       Social    986     Multi  None\n",
       "1       munmun_digg_reply  D-rep       Social  30398    Simple  None\n",
       "2         opsahi-ucsocial     UC  Information   1899     Multi  None\n",
       "3          radoslaw_email   Rado       Social    167     Multi  None\n",
       "4   soc-sign-bitcoinalpha   bitA       Social   3783    Simple  None\n",
       "5         sx-mathoverflow  SX-MO       Social  24818     Multi  None"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "9dad6e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Таблица признаков для графа\n",
    "\n",
    "def get_stats(network_file_name: str):\n",
    "    \n",
    "    tmpGraph = graphs.TemporalGraph(network_file_name)\n",
    "    staticGraph = tmpGraph.get_static_graph(0.2, 0.6)\n",
    "    snowball_sample_approach = graphs.SelectApproach(0, 5)\n",
    "    random_selected_vertices_approach = graphs.SelectApproach()\n",
    "    sg_sb = snowball_sample_approach(staticGraph.get_largest_connected_component())\n",
    "    sg_rsv = random_selected_vertices_approach(staticGraph.get_largest_connected_component())\n",
    "    \n",
    "    # ск - снежный ком\n",
    "    # свв - случайный выбор вершин\n",
    "    return {\n",
    "        'Сеть': network_file_name['Label'],\n",
    "        'Категория': network_file_name['Category'],\n",
    "        'Вершины': staticGraph.count_vertices(), \n",
    "        'Тип ребер': network_file_name['Edge type'],\n",
    "        'Ребра':staticGraph.count_edges(),\n",
    "        'Плотность графа':staticGraph.density(),\n",
    "        'Доля вершин':staticGraph.share_of_vertices(),\n",
    "        'Компоненты с/с':staticGraph.get_number_of_connected_components(),\n",
    "        'Вершины в наибольшей компоненте с/с':staticGraph.get_largest_connected_component().count_vertices(),\n",
    "        'Ребра в наибольшей компоненте с/с':staticGraph.get_largest_connected_component().count_edges(),\n",
    "        'Радиус графа(ск)': staticGraph.get_radius(sg_sb),\n",
    "        'Диаметр графа(ск)': staticGraph.get_diameter(sg_sb),\n",
    "        '90 проц. расстояния(ск)': staticGraph.percentile_distance(sg_sb),\n",
    "        'Радиус графа(свв)': staticGraph.get_radius(sg_rsv),\n",
    "        'Диаметр графа(свв)': staticGraph.get_diameter(sg_rsv),\n",
    "        '90 проц.расстояния(свв)': staticGraph.percentile_distance(sg_rsv),\n",
    "        'Коэф.ассортативности': staticGraph.assortative_factor(),\n",
    "        'Сред.класт.коэф.сети': staticGraph.average_cluster_factor(),\n",
    "        'AUC': get_performance(tmpGraph),\n",
    "    }\n",
    "\n",
    "def graph_features_tables(datasets_info: pd.DataFrame):\n",
    "\n",
    "    table = pd.DataFrame([get_stats(network) for index, network in datasets_info.iterrows()]).sort_values('Вершины')\n",
    "    \n",
    "    columns_to_include_to_feature_network_table = [\n",
    "        'Сеть',\n",
    "        'Категория',\n",
    "        'Вершины', \n",
    "        'Тип ребер',\n",
    "        'Ребра',\n",
    "        'Плотность графа',\n",
    "        'Доля вершин',\n",
    "        'Компоненты с/с',\n",
    "        'Вершины в наибольшей компоненте с/с',\n",
    "        'Ребра в наибольшей компоненте с/с',\n",
    "        'Радиус графа(ск)',\n",
    "        'Диаметр графа(ск)',\n",
    "        '90 проц. расстояния(ск)',\n",
    "        'Радиус графа(свв)',\n",
    "        'Диаметр графа(свв)',\n",
    "        '90 проц.расстояния(свв)',\n",
    "        'Коэф.ассортативности',\n",
    "        'Сред.класт.коэф.сети',\n",
    "    ]\n",
    "    columns_to_include_to_auc_table = [\n",
    "        'Сеть',\n",
    "        'AUC',\n",
    "    ]\n",
    "    latex_feature_network_table = table.to_latex(\n",
    "        formatters={\n",
    "            'Вершины': lambda x: f'{x:,}', \n",
    "            'Ребра': lambda x: f'{x:,}',\n",
    "            'Плотность графа': lambda x: f'{x:.2f}',\n",
    "            'Доля вершин': lambda x: f'{x:.2f}',\n",
    "            'Компоненты с/с': lambda x: f'{x:,}',\n",
    "            'Вершины в наибольшей компоненте с/с': lambda x: f'{x:,}',\n",
    "            'Ребра в наибольшей компоненте с/с': lambda x: f'{x:,}',\n",
    "            'Радиус графа(ск)': lambda x: f'{x:.2f}',\n",
    "            'Диаметр графа(ск)': lambda x: f'{x:.2f}',\n",
    "            '90 проц. расстояния(ск)': lambda x: f'{x:.2f}',\n",
    "            'Радиус графа(свв)': lambda x: f'{x:.2f}',\n",
    "            'Диаметр графа(свв)': lambda x: f'{x:.2f}',\n",
    "            '90 проц.расстояния(свв)': lambda x: f'{x:.2f}',\n",
    "            'Коэф.ассортативности': lambda x: f'{x:.2f}',\n",
    "            'Сред.класт.коэф.сети': lambda x: f'{x:.2f}',\n",
    "        },\n",
    "        column_format='l@{\\hspace{1em}}c@{\\hspace{1em}}c@{\\hspace{0.5em}}r@{\\hspace{1em}}r@{\\hspace{1em}}c@{\\hspace{1em}}c@{\\hspace{1em}}c@{\\hspace{1em}}c@{\\hspace{0.5em}}c',\n",
    "        index=False,\n",
    "        caption=(\n",
    "            \"Признаки для сетей, рассмотренных в ходе работы \"\n",
    "        ),\n",
    "        label='Таблица: Признаки сетей',\n",
    "        escape=False,\n",
    "        multicolumn=False,\n",
    "        columns=columns_to_include_to_feature_network_table\n",
    "    )\n",
    "    latex_auc_table = table.to_latex(\n",
    "        formatters={\n",
    "            'AUC': lambda x: f'{x:.2f}',\n",
    "        },\n",
    "        column_format='l@{\\hspace{1em}}c@{\\hspace{1em}}c@{\\hspace{0.5em}}r@{\\hspace{1em}}r@{\\hspace{1em}}c@{\\hspace{1em}}c@{\\hspace{1em}}c@{\\hspace{1em}}c@{\\hspace{0.5em}}c',\n",
    "        index=False,\n",
    "        caption=(\n",
    "            \"Точность пердсказания появления ребер\"\n",
    "        ),\n",
    "        label='Таблица: AUC',\n",
    "        escape=False,\n",
    "        multicolumn=False,\n",
    "        columns=columns_to_include_to_auc_table\n",
    "    )\n",
    "    return (latex_feature_network_table,latex_auc_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
